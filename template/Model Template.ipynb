{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1600629207952",
   "display_name": "Python 3.7.9 64-bit ('tfenv': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title\n",
    "notebook description."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "In this section useful libraries are imported which are used in most data science projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# sets the path to the home directory of this repository so other modules can be imported. \n",
    "project_path = os.getcwd()\n",
    "root_path = os.path.split(os.path.split(os.getcwd())[0])[0]\n",
    "assert root_path.endswith(\"Fontys-ADS\"), \"The root path does not end with Fontys-ADS: \" + root_path \n",
    "sys.path.insert(0, root_path)\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# set the seed for reproducible results.\n",
    "np.random.seed(56)\n",
    "tf.random.set_seed(56)\n",
    "\n",
    "# optionally, set TensorFlow to use the GPU with all available memory.\n",
    "# physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "# tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data collection\n",
    "explain how to gather the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "     target  feature1  feature2\n0         0        12        -4\n1         1        43        14\n2         0        11        -4\n3         1        77        16\n4         0        12        12\n..      ...       ...       ...\n795       1        77        16\n796       0        12        12\n797       1        43        43\n798       0        11        11\n799       1        77        77\n\n[800 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n      <th>feature1</th>\n      <th>feature2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>12</td>\n      <td>-4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>43</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>11</td>\n      <td>-4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>77</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>12</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>795</th>\n      <td>1</td>\n      <td>77</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>796</th>\n      <td>0</td>\n      <td>12</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>797</th>\n      <td>1</td>\n      <td>43</td>\n      <td>43</td>\n    </tr>\n    <tr>\n      <th>798</th>\n      <td>0</td>\n      <td>11</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>799</th>\n      <td>1</td>\n      <td>77</td>\n      <td>77</td>\n    </tr>\n  </tbody>\n</table>\n<p>800 rows Ã— 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'target': [0, 1, 0, 1, 0, 1, 0, 1] * 100, 'feature1': [12, 43, 11, 77, 12, 43, 11, 77] * 100, 'feature2': [-4, 14, -4, 16, 12, 43, 11, 77] * 100})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the data\n",
    "explain how the data is prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.base_dataset import DatasetBase\n",
    "\n",
    "# the dataset class\n",
    "class MyDataset(DatasetBase):\n",
    "    def __init__(self, df, batch_size, train_percentage, validation_percentage, test_percentage):\n",
    "        # sets the batch size\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        features = tf.cast(df.loc[:, df.columns != 'target'].values, tf.float32)\n",
    "        labels = tf.cast(df.loc[:, 'target'].values, tf.bool)\n",
    "\n",
    "        # sets the data.\n",
    "        self.data = tf.data.Dataset.from_tensor_slices((features, labels))\n",
    "\n",
    "        # set the feature length.\n",
    "        self.feature_length = len(df.columns) - 1\n",
    "        \n",
    "        # shuffles the dataset\n",
    "        self.shuffle(256)\n",
    "\n",
    "        # splits the data into train, validation, and test datasets.\n",
    "        self.split_data_to_train_val_test(self.data, train_percentage, validation_percentage, test_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "train: 240 validation: 80 test: 80\n"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "train_percentage = 0.6\n",
    "validation_percentage = 0.2\n",
    "test_percentage = 0.2\n",
    "myDataset = MyDataset(df, batch_size, train_percentage, validation_percentage, test_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "Explore the data to gain insights on possible features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling\n",
    "Apply ML/DL models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.base_model import ModelBase\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "\n",
    "class MyModel(ModelBase):\n",
    "    def __init__(self, feature_length, gpu_initialized=False, training=False, limit=5000):\n",
    "        super().__init__(gpu_initialized, training, limit)\n",
    "        # the name for the model.\n",
    "        self.name = 'MyModel'\n",
    "\n",
    "        # sets the feature length for input.\n",
    "        self.feature_length = feature_length\n",
    "\n",
    "    def predict(self, X):\n",
    "        # create predictable array, since predicting only works on an array.\n",
    "        predictable_array = np.expand_dims(X, axis=0)\n",
    "\n",
    "        # perform prediction and take the first and only prediction out of the predictions array.\n",
    "        prediction = self.model.predict(X, verbose=1)[0]\n",
    "        \n",
    "        return prediction\n",
    "\n",
    "    def fit(self, training, callbacks, epochs, validation, validation_steps, steps_per_epoch):\n",
    "        self.model.fit(\n",
    "            training,\n",
    "            callbacks=callbacks,\n",
    "            epochs=epochs,\n",
    "            validation_data=validation,\n",
    "            validation_steps=validation_steps,\n",
    "            steps_per_epoch=steps_per_epoch, verbose=0)\n",
    "\n",
    "    def compile(self, optimizer='adam', loss='mse', metrics=['mse'], loss_weights=[1.0], show_summary=False):\n",
    "        inputs = Input((self.feature_length,))\n",
    "\n",
    "        dense1 = Dense(64, activation='relu', kernel_initializer='glorot_uniform')(inputs)\n",
    "        outputs = Dense(1, activation='sigmoid', kernel_initializer='glorot_uniform')(dense1)\n",
    "\n",
    "        # construct the model by stitching the inputs and outputs\n",
    "        self.model = Model(inputs=inputs, outputs=outputs, name=self.name)\n",
    "\n",
    "        # compile the model\n",
    "        self.model.compile(optimizer=optimizer, loss=loss, metrics=metrics, loss_weights=loss_weights)\n",
    "\n",
    "        if show_summary:\n",
    "            self.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(myDataset.feature_length, training=True, gpu_initialized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"MyModel\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 2)]               0         \n_________________________________________________________________\ndense (Dense)                (None, 64)                192       \n_________________________________________________________________\ndense_1 (Dense)              (None, 1)                 65        \n=================================================================\nTotal params: 257\nTrainable params: 257\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "import datetime\n",
    "\n",
    "epochs = 512\n",
    "INIT_LR = 1e-4\n",
    "opt = Adam(lr = INIT_LR, decay = INIT_LR / epochs)\n",
    "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['mse', 'accuracy'], show_summary=True)\n",
    "\n",
    "# current time\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# create logging\n",
    "log_dir = os.path.join(project_path, f'logs\\{model.name}\\{current_time}')\n",
    "\n",
    "# create all callbacks\n",
    "callbacks = [\n",
    "  EarlyStopping(patience=50, monitor='val_loss'),\n",
    "  TensorBoard(log_dir=log_dir, profile_batch=0)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fit the model using the training data\n",
    "results = model.fit(\n",
    "  training=myDataset.train_ds,\n",
    "  callbacks=callbacks,\n",
    "  epochs=epochs,\n",
    "  validation=myDataset.val_ds,\n",
    "  validation_steps=myDataset.val_size,\n",
    "  steps_per_epoch=myDataset.train_size)\n",
    "  \n",
    "# save the weights of the model\n",
    "weights_path = os.path.join(project_path, f'models\\{model.name}_trained_model_weights')\n",
    "model.save_weights(weights_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation\n",
    "Validate the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n# Evaluate on test data\n70/70 [==============================] - 0s 2ms/step - loss: 4.6073e-09 - mse: 1.1064e-18 - accuracy: 1.0000\ntest loss, test acc: [4.607292541340698e-09, 1.1063724e-18, 1.0]\n{'loss': 4.607292541340698e-09, 'mse': 1.1063724e-18, 'accuracy': 1.0}\n"
    }
   ],
   "source": [
    "# re initialize the model.\n",
    "model.training = False\n",
    "model.compile(optimizer=Adam(lr = 1e-4), loss='binary_crossentropy', metrics=['mse', 'accuracy'], show_summary=False) \n",
    "model.load_weights(weights_path)\n",
    "\n",
    "print('\\n# Evaluate on test data')\n",
    "result = model.evaluate(myDataset.actual_test_ds)\n",
    "print('test loss, test acc:', result)\n",
    "res = dict(zip(model.get_metric_names(), result))\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}