{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Building and saving deep learning models\n",
    "In this notebook all the deep learning models will be built and persisted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import pathlib\n",
    "\n",
    "# sets the path to the home directory of this repository so other modules can be imported. \n",
    "root_path = os.path.split(os.getcwd())[0]\n",
    "assert root_path.endswith(\"mask-detection\"), \"The root path does not end with mask-detection: \" + root_path \n",
    "sys.path.insert(0, root_path)\n",
    "\n",
    "# set the seed for reproducible results.\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "# GPU settings\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train: 36 validation: 12 test: 12\n",
      "train: 308 validation: 102 test: 102\n"
     ]
    }
   ],
   "source": [
    "# Facemask detection dataset\n",
    "from datasets.facemask_dataset import FacemaskDataset\n",
    "batch_size = 64\n",
    "train_percentage = 0.6\n",
    "validation_percentage = 0.2\n",
    "test_percentage = 0.2\n",
    "detection_ds_path = pathlib.Path(root_path + '/data/facemask-dataset')\n",
    "detection_ds = FacemaskDataset(detection_ds_path, batch_size, 200, 200, True, train_percentage, validation_percentage, test_percentage)\n",
    "\n",
    "# Facemask judge dataset\n",
    "from datasets.facemask_net_dataset import FacemaskNetDataset\n",
    "batch_size = 256\n",
    "judge_ds_path = pathlib.Path(root_path + '/data/facemask-net-dataset')\n",
    "judge_ds = FacemaskNetDataset(judge_ds_path, batch_size, train_percentage, validation_percentage, test_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Facemask detection CNN\n",
    "A CNN which will be used for face mask detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_model = tf.keras.Sequential([\n",
    "    layers.experimental.preprocessing.Rescaling(1./255),\n",
    "    Conv2D(32, 3, activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Dropout(0.3),\n",
    "    Conv2D(32, 3, activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Dropout(0.3),\n",
    "    Conv2D(32, 3, activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Dropout(0.3),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "detection_model.compile(\n",
    "    optimizer=Adam(),\n",
    "    loss=BinaryCrossentropy(),\n",
    "    metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "36/36 [==============================] - 57s 2s/step - loss: 0.6928 - acc: 0.5213 - val_loss: 0.6925 - val_acc: 0.6810\n",
      "Epoch 2/100\n",
      "36/36 [==============================] - 2s 46ms/step - loss: 0.6901 - acc: 0.5573 - val_loss: 0.6875 - val_acc: 0.7318\n",
      "Epoch 3/100\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.6807 - acc: 0.5907 - val_loss: 0.6720 - val_acc: 0.6849\n",
      "Epoch 4/100\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.6583 - acc: 0.6549 - val_loss: 0.6379 - val_acc: 0.7148\n",
      "Epoch 5/100\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.6204 - acc: 0.6918 - val_loss: 0.5864 - val_acc: 0.7578\n",
      "Epoch 6/100\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.5688 - acc: 0.7357 - val_loss: 0.5303 - val_acc: 0.7760\n",
      "Epoch 7/100\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.5163 - acc: 0.7643 - val_loss: 0.4874 - val_acc: 0.8372\n",
      "Epoch 8/100\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.4500 - acc: 0.8220 - val_loss: 0.5050 - val_acc: 0.7435\n",
      "Epoch 9/100\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.3973 - acc: 0.8429 - val_loss: 0.5165 - val_acc: 0.7096\n",
      "Epoch 10/100\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.3602 - acc: 0.8628 - val_loss: 0.4800 - val_acc: 0.7487\n",
      "Epoch 11/100\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.3294 - acc: 0.8772 - val_loss: 0.4711 - val_acc: 0.7565\n",
      "Epoch 12/100\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.3158 - acc: 0.8759 - val_loss: 0.4683 - val_acc: 0.7578\n",
      "Epoch 13/100\n",
      "36/36 [==============================] - 2s 45ms/step - loss: 0.3082 - acc: 0.8815 - val_loss: 0.4387 - val_acc: 0.7943\n",
      "Epoch 14/100\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.3025 - acc: 0.8806 - val_loss: 0.3918 - val_acc: 0.8346\n",
      "Epoch 15/100\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.2928 - acc: 0.8876 - val_loss: 0.3684 - val_acc: 0.8542\n",
      "Epoch 16/100\n",
      "36/36 [==============================] - 2s 45ms/step - loss: 0.2831 - acc: 0.8928 - val_loss: 0.3863 - val_acc: 0.8398\n",
      "Epoch 17/100\n",
      "36/36 [==============================] - 2s 45ms/step - loss: 0.2823 - acc: 0.8885 - val_loss: 0.3647 - val_acc: 0.8542\n",
      "Epoch 18/100\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.2811 - acc: 0.8902 - val_loss: 0.3526 - val_acc: 0.8620\n",
      "Epoch 19/100\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.2749 - acc: 0.8967 - val_loss: 0.3285 - val_acc: 0.8776\n",
      "Epoch 20/100\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.2740 - acc: 0.8945 - val_loss: 0.3348 - val_acc: 0.8763\n",
      "Epoch 21/100\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.2686 - acc: 0.8963 - val_loss: 0.3108 - val_acc: 0.8893\n",
      "Epoch 22/100\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.2672 - acc: 0.8967 - val_loss: 0.3035 - val_acc: 0.8893\n",
      "Epoch 23/100\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.2630 - acc: 0.8984 - val_loss: 0.3133 - val_acc: 0.8815\n",
      "Epoch 24/100\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.2658 - acc: 0.8958 - val_loss: 0.3143 - val_acc: 0.8841\n",
      "Epoch 25/100\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.2585 - acc: 0.9010 - val_loss: 0.2842 - val_acc: 0.9036\n",
      "Epoch 26/100\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.2593 - acc: 0.9019 - val_loss: 0.2917 - val_acc: 0.8932\n",
      "Epoch 27/100\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.2546 - acc: 0.9010 - val_loss: 0.2911 - val_acc: 0.8932\n",
      "Epoch 28/100\n",
      "36/36 [==============================] - 2s 46ms/step - loss: 0.2587 - acc: 0.9015 - val_loss: 0.2826 - val_acc: 0.9049\n",
      "Epoch 29/100\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.2543 - acc: 0.9028 - val_loss: 0.2813 - val_acc: 0.9049\n",
      "Epoch 30/100\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.2568 - acc: 0.9010 - val_loss: 0.2734 - val_acc: 0.9049\n",
      "Epoch 31/100\n",
      "36/36 [==============================] - 2s 43ms/step - loss: 0.2547 - acc: 0.8997 - val_loss: 0.2705 - val_acc: 0.9049\n",
      "Epoch 32/100\n",
      "36/36 [==============================] - 2s 43ms/step - loss: 0.2497 - acc: 0.9067 - val_loss: 0.2685 - val_acc: 0.9049\n",
      "Epoch 33/100\n",
      "36/36 [==============================] - 2s 47ms/step - loss: 0.2521 - acc: 0.9054 - val_loss: 0.2625 - val_acc: 0.9076\n",
      "Epoch 34/100\n",
      "36/36 [==============================] - 2s 45ms/step - loss: 0.2499 - acc: 0.9032 - val_loss: 0.2642 - val_acc: 0.9062\n",
      "Epoch 35/100\n",
      "36/36 [==============================] - 2s 46ms/step - loss: 0.2539 - acc: 0.9049 - val_loss: 0.2577 - val_acc: 0.9089\n",
      "Epoch 36/100\n",
      "36/36 [==============================] - 2s 43ms/step - loss: 0.2485 - acc: 0.9071 - val_loss: 0.2633 - val_acc: 0.9036\n",
      "Epoch 37/100\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.2516 - acc: 0.9049 - val_loss: 0.2662 - val_acc: 0.9036\n",
      "Epoch 38/100\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.2481 - acc: 0.9054 - val_loss: 0.2531 - val_acc: 0.9089\n",
      "Epoch 39/100\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.2459 - acc: 0.9058 - val_loss: 0.2537 - val_acc: 0.9062\n",
      "Epoch 40/100\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.2464 - acc: 0.9054 - val_loss: 0.2491 - val_acc: 0.9076\n",
      "Epoch 41/100\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.2449 - acc: 0.9067 - val_loss: 0.2434 - val_acc: 0.9115\n",
      "Epoch 42/100\n",
      "36/36 [==============================] - 2s 43ms/step - loss: 0.2456 - acc: 0.9080 - val_loss: 0.2456 - val_acc: 0.9089\n",
      "Epoch 43/100\n",
      "36/36 [==============================] - 2s 43ms/step - loss: 0.2396 - acc: 0.9080 - val_loss: 0.2431 - val_acc: 0.9102\n",
      "Epoch 44/100\n",
      "36/36 [==============================] - 2s 43ms/step - loss: 0.2425 - acc: 0.9089 - val_loss: 0.2467 - val_acc: 0.9076\n",
      "Epoch 45/100\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.2426 - acc: 0.9076 - val_loss: 0.2395 - val_acc: 0.9115\n",
      "Epoch 46/100\n",
      "36/36 [==============================] - 2s 45ms/step - loss: 0.2408 - acc: 0.9093 - val_loss: 0.2349 - val_acc: 0.9141\n",
      "Epoch 47/100\n",
      "36/36 [==============================] - 2s 45ms/step - loss: 0.2340 - acc: 0.9093 - val_loss: 0.2379 - val_acc: 0.9115\n",
      "Epoch 48/100\n",
      "36/36 [==============================] - 2s 45ms/step - loss: 0.2400 - acc: 0.9084 - val_loss: 0.2358 - val_acc: 0.9141\n",
      "Epoch 49/100\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.2368 - acc: 0.9119 - val_loss: 0.2319 - val_acc: 0.9141\n",
      "Epoch 50/100\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.2354 - acc: 0.9123 - val_loss: 0.2293 - val_acc: 0.9154\n",
      "Epoch 51/100\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.2326 - acc: 0.9110 - val_loss: 0.2279 - val_acc: 0.9154\n",
      "Epoch 52/100\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.2350 - acc: 0.9110 - val_loss: 0.2260 - val_acc: 0.9154\n",
      "Epoch 53/100\n",
      "36/36 [==============================] - 2s 43ms/step - loss: 0.2339 - acc: 0.9076 - val_loss: 0.2280 - val_acc: 0.9154\n",
      "Epoch 54/100\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.2290 - acc: 0.9110 - val_loss: 0.2252 - val_acc: 0.9167\n",
      "Epoch 55/100\n",
      "36/36 [==============================] - 2s 43ms/step - loss: 0.2331 - acc: 0.9123 - val_loss: 0.2220 - val_acc: 0.9154\n",
      "Epoch 56/100\n",
      "36/36 [==============================] - 2s 43ms/step - loss: 0.2309 - acc: 0.9145 - val_loss: 0.2212 - val_acc: 0.9167\n",
      "Epoch 57/100\n",
      "36/36 [==============================] - 2s 46ms/step - loss: 0.2284 - acc: 0.9132 - val_loss: 0.2203 - val_acc: 0.9167\n",
      "Epoch 58/100\n",
      "36/36 [==============================] - 2s 45ms/step - loss: 0.2286 - acc: 0.9136 - val_loss: 0.2188 - val_acc: 0.9167\n",
      "Epoch 59/100\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.2244 - acc: 0.9154 - val_loss: 0.2183 - val_acc: 0.9167\n",
      "Epoch 60/100\n",
      "36/36 [==============================] - 2s 43ms/step - loss: 0.2260 - acc: 0.9128 - val_loss: 0.2158 - val_acc: 0.9167\n",
      "Epoch 61/100\n",
      "36/36 [==============================] - 2s 45ms/step - loss: 0.2246 - acc: 0.9136 - val_loss: 0.2155 - val_acc: 0.9167\n",
      "Epoch 62/100\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.2260 - acc: 0.9149 - val_loss: 0.2141 - val_acc: 0.9167\n",
      "Epoch 63/100\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.2221 - acc: 0.9136 - val_loss: 0.2130 - val_acc: 0.9180\n",
      "Epoch 64/100\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.2226 - acc: 0.9171 - val_loss: 0.2112 - val_acc: 0.9232\n",
      "Epoch 65/100\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.2197 - acc: 0.9162 - val_loss: 0.2115 - val_acc: 0.9167\n",
      "Epoch 66/100\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.2206 - acc: 0.9132 - val_loss: 0.2093 - val_acc: 0.9245\n",
      "Epoch 67/100\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.2183 - acc: 0.9141 - val_loss: 0.2089 - val_acc: 0.9154\n",
      "Epoch 68/100\n",
      "36/36 [==============================] - 2s 48ms/step - loss: 0.2207 - acc: 0.9162 - val_loss: 0.2071 - val_acc: 0.9245\n",
      "Epoch 69/100\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.2172 - acc: 0.9158 - val_loss: 0.2060 - val_acc: 0.9232\n",
      "Epoch 70/100\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.2167 - acc: 0.9154 - val_loss: 0.2047 - val_acc: 0.9258\n",
      "Epoch 71/100\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.2149 - acc: 0.9180 - val_loss: 0.2037 - val_acc: 0.9271\n",
      "Epoch 72/100\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.2140 - acc: 0.9193 - val_loss: 0.2025 - val_acc: 0.9271\n",
      "Epoch 73/100\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.2194 - acc: 0.9162 - val_loss: 0.2017 - val_acc: 0.9271\n",
      "Epoch 74/100\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.2111 - acc: 0.9210 - val_loss: 0.2003 - val_acc: 0.9271\n",
      "Epoch 75/100\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.2162 - acc: 0.9145 - val_loss: 0.1999 - val_acc: 0.9284\n",
      "Epoch 76/100\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.2111 - acc: 0.9206 - val_loss: 0.1989 - val_acc: 0.9271\n",
      "Epoch 77/100\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.2087 - acc: 0.9197 - val_loss: 0.1971 - val_acc: 0.9232\n",
      "Epoch 78/100\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.2086 - acc: 0.9232 - val_loss: 0.1964 - val_acc: 0.9284\n",
      "Epoch 79/100\n",
      "36/36 [==============================] - 2s 45ms/step - loss: 0.2066 - acc: 0.9201 - val_loss: 0.1948 - val_acc: 0.9284\n",
      "Epoch 80/100\n",
      "36/36 [==============================] - 2s 45ms/step - loss: 0.2085 - acc: 0.9214 - val_loss: 0.1948 - val_acc: 0.9284\n",
      "Epoch 81/100\n",
      "36/36 [==============================] - 2s 45ms/step - loss: 0.2050 - acc: 0.9184 - val_loss: 0.1936 - val_acc: 0.9245\n",
      "Epoch 82/100\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.2063 - acc: 0.9167 - val_loss: 0.1941 - val_acc: 0.9284\n",
      "Epoch 83/100\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.2053 - acc: 0.9210 - val_loss: 0.1908 - val_acc: 0.9284\n",
      "Epoch 84/100\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.2000 - acc: 0.9232 - val_loss: 0.1903 - val_acc: 0.9297\n",
      "Epoch 85/100\n",
      "36/36 [==============================] - 2s 46ms/step - loss: 0.2024 - acc: 0.9227 - val_loss: 0.1898 - val_acc: 0.9297\n",
      "Epoch 86/100\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.2010 - acc: 0.9240 - val_loss: 0.1883 - val_acc: 0.9284\n",
      "Epoch 87/100\n",
      "36/36 [==============================] - 2s 46ms/step - loss: 0.2013 - acc: 0.9253 - val_loss: 0.1877 - val_acc: 0.9297\n",
      "Epoch 88/100\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.1984 - acc: 0.9227 - val_loss: 0.1860 - val_acc: 0.9297\n",
      "Epoch 89/100\n",
      "36/36 [==============================] - 2s 45ms/step - loss: 0.1956 - acc: 0.9258 - val_loss: 0.1849 - val_acc: 0.9297\n",
      "Epoch 90/100\n",
      "36/36 [==============================] - 2s 45ms/step - loss: 0.1916 - acc: 0.9258 - val_loss: 0.1830 - val_acc: 0.9297\n",
      "Epoch 91/100\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.1973 - acc: 0.9236 - val_loss: 0.1827 - val_acc: 0.9297\n",
      "Epoch 92/100\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.1918 - acc: 0.9262 - val_loss: 0.1822 - val_acc: 0.9323\n",
      "Epoch 93/100\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.1966 - acc: 0.9253 - val_loss: 0.1820 - val_acc: 0.9349\n",
      "Epoch 94/100\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.2000 - acc: 0.9201 - val_loss: 0.1843 - val_acc: 0.9310\n",
      "Epoch 95/100\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.1956 - acc: 0.9266 - val_loss: 0.1800 - val_acc: 0.9349\n",
      "Epoch 96/100\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.1921 - acc: 0.9280 - val_loss: 0.1783 - val_acc: 0.9297\n",
      "Epoch 97/100\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.1900 - acc: 0.9232 - val_loss: 0.1788 - val_acc: 0.9362\n",
      "Epoch 98/100\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.1905 - acc: 0.9262 - val_loss: 0.1839 - val_acc: 0.9297\n",
      "Epoch 99/100\n",
      "36/36 [==============================] - 2s 45ms/step - loss: 0.1860 - acc: 0.9253 - val_loss: 0.1770 - val_acc: 0.9362\n",
      "Epoch 100/100\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.1883 - acc: 0.9245 - val_loss: 0.1784 - val_acc: 0.9336\n"
     ]
    }
   ],
   "source": [
    "# Add a callback for earlystopping\n",
    "callbacks = [EarlyStopping(patience=10, monitor='val_loss')]\n",
    "\n",
    "detection_history = detection_model.fit(\n",
    "    x=detection_ds.train_ds,\n",
    "    validation_data=detection_ds.val_ds,\n",
    "    epochs=100,\n",
    "    validation_steps=detection_ds.val_size,\n",
    "    steps_per_epoch=detection_ds.train_size,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Facemask Judge CNN\n",
    "A CNN which will be used for judging if a face mask is correctly worn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge_model = tf.keras.Sequential([\n",
    "    layers.experimental.preprocessing.Rescaling(1./255),\n",
    "    Conv2D(32, 3, activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(64, 3, activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(128, 3, activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Flatten(),\n",
    "    Dense(236, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "judge_model.compile(\n",
    "    optimizer=Adam(),\n",
    "    loss=BinaryCrossentropy(),\n",
    "    metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "1233/1233 [==============================] - 1295s 1s/step - loss: 0.2064 - acc: 0.9121 - val_loss: 0.0584 - val_acc: 0.9864\n",
      "Epoch 2/100\n",
      "1233/1233 [==============================] - 488s 396ms/step - loss: 0.0448 - acc: 0.9868 - val_loss: 0.0302 - val_acc: 0.9925\n",
      "Epoch 3/100\n",
      "  77/1233 [>.............................] - ETA: 2:29 - loss: 0.0430 - acc: 0.9868"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-3af1444014d4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m judge_history = judge_model.fit(\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjudge_ds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjudge_ds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "judge_history = judge_model.fit(\n",
    "    x=judge_ds.train_ds,\n",
    "    validation_data=judge_ds.val_ds,\n",
    "    epochs=50,\n",
    "    validation_steps=judge_ds.val_size,\n",
    "    steps_per_epoch=judge_ds.train_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise_results(history):\n",
    "    def plot_graph(history, metric, label):\n",
    "        plt.plot(history.history[metric])\n",
    "        plt.plot(history.history['val_'+metric], '')\n",
    "        plt.xlabel(\"epochs\", fontsize=15)\n",
    "        plt.ylabel(label, fontsize=15)\n",
    "        plt.legend([f'training {label}', f'validation {label}'])\n",
    "\n",
    "    fig = plt.figure(figsize=(16,8))\n",
    "    fig.suptitle(\"Training metrics\", fontsize=20)\n",
    "    plt.subplot(1,2,1)\n",
    "    plot_graph(history, 'acc', 'accuracy')\n",
    "    plt.ylim(None,1)\n",
    "    plt.subplot(1,2,2)\n",
    "    plot_graph(history, 'loss', 'loss')\n",
    "    plt.ylim(0,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise_results(detection_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise_results(judge_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_model.save(root_path + '/models/detection_cnn')\n",
    "judge_model.save(root_path + '/models/judge_cnn')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.0 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "ece2f41b18fa8c12c51e3a931b80732f40826f87ac38ad89429e85a1f7e749da"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}